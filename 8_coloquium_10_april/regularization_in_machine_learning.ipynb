{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc0053",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/12_coloquio_machine_learnig/blob/main/8_coloquium_10_april/regularization_in_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2c746",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [Video de apoyo a la lectura de este cuaderno jupyter]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cc98e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Regularization en machine learning](https://medium.com/@roiyeho/regularization-19b1879415a1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77da9c99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regularization is a widespread technique that is used in many machine learning models to control the complexity of the model and thereby improve its generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e38519",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this article I’m going to explain the concept of regularization in depth, and demonstrate its usage in several machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31555d1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c32e79",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regularization is a technique to prevent overfitting by penalizing complex models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a9acb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The idea is to add a penalty term to the cost function of the model, such that it becomes dependent on two factors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ae2a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ Cost(h) = \\text{training_error}(h) + \\lambda \\ \\text{Complexity}(h) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905038c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\lambda$ is a hyperparameter (called the regularization coefficient) that controls the tradeoff between the bias and the variance (for a discussion on the bias-variance tradeoff see my previous article). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fefd10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Higher $\\lambda$ will induce a larger penalty on the complexity of the model, and thus will lead to simpler models with higher error on the training set but with smaller variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bac073",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The complexity of the model can be measured in a variety of ways. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a85f42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, in models that consist of a vector of parameters (weights) $w$, such as linear regression or neural networks, we use the size of the parameters (the norm of the vector $w$) as a measure for the model’s complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f3b0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In such models, there are two common types of regularization, depending on the norm of the vector w that we are using:\n",
    "\n",
    "1. **$L1$ regularization**. In this case, we use the $L1$ norm of the vector $w$, i.e., the sum of the absolute values of the weights.  \n",
    "\n",
    "For example, in linear regression, if we have $m$ features in our data set, then the model will have m parameters (weights) plus a bias term, thus we can write the L1 norm of w as:\n",
    "\n",
    "$$ \\Vert w \\Vert_{1} = |w_{0}| + |w_{1}| + \\cdots + |w_{m}| $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab277fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. **Regularización L2**. En este caso, usamos la norma L2 del vector w (al cuadrado), es decir, la suma de los cuadrados de los pesos:  \n",
    "\n",
    "$$ \\Vert w \\Vert_{2}^{2} = w_{0}^{2} + w_{1}^{2} + \\cdot + w_{m}^{2}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1451f4f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En general, la regularización $L1$ es una forma más fuerte de regularización que $L2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62ea22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En la regularización $L1$, la velocidad a la que los pesos caen a 0 es constante (ya que el gradiente de $|WJ|$ es $1$), mientras que en la regularización $L2$, la tasa se vuelve más lenta a medida que los pesos se acercan a 0 (ya que el gradiente de $w_{j}^{2}$ es $2wj$). Por lo tanto, es más probable que L1 ponga a cero algunos de los pesos, eliminando efectivamente sus características asociadas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9232eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingrese un numero: hola\n",
      "ingrese un numero: 3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a = input('ingrese un numero: ')\n",
    "b = input('ingrese un numero: ')\n",
    "\n",
    "try:\n",
    "    primero = int(a)\n",
    "except ValueError:\n",
    "    a = 'chanchito feliz'\n",
    "try:\n",
    "    segundo = int(b)\n",
    "except ValueError:\n",
    "    b = 'chanchito feliz'\n",
    "    \n",
    "if (a!= 'chanchito feliz') or (b!='chanchito feliz'):\n",
    "    print(primero + segundo)\n",
    "else:\n",
    "    print('no has ingresado bien los números')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ea0adc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'hola'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2208\\3312016030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hola'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'hola'"
     ]
    }
   ],
   "source": [
    "int('hola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f5c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3ec29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0d8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ee37a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
