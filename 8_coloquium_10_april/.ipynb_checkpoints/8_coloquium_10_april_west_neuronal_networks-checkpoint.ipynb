{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc06dec7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/1_algebra/blob/main/classes/ciencia_datos/6_class_march_15_quiz_1/5_class_march_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5b198",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Video de apoyo a la lectura interactiva y experimental de este cuaderno]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e82203",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [Vínculo al programa del curso:  ]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46c23b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelo general de clase: [aula invertida](https://www3.gobiernodecanarias.org/medusa/ecoescuela/pedagotic/aprendizaje-invertido-flipped-classroom/)\n",
    "\n",
    "## Definición y características de este modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0e776",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Qué es?  \n",
    "\n",
    "Flipped Learning o aprendizaje invertido es un enfoque pedagógico en el que:  \n",
    "\n",
    "* la instrucción directa se realiza fuera del aula y \n",
    "* se utiliza el tiempo de clase para llevar a cabo actividades que impliquen el desarrollo de procesos cognitivos de mayor complejidad, en las que son necesarias la ayuda y la experiencia del docente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4f731",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Para qué sirve?  \n",
    "\n",
    "Mejora el proceso de enseñanza-aprendizaje realizando,   \n",
    "\n",
    "* fuera del aula, actividades de aprendizaje sencillas (observar, memorizar, resumir, etc.) y, \n",
    "* en el aula, actividades más complejas (razonar, examinar, priorizar, argumentar, proponer, etc.) que requieren la interacción entre iguales y la ayuda del docente como facilitador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42472d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/7_didactica_ciencia_datos/blob/main/propuesta/unidad_didac/atributos_aprendizaje_invertido.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84edf3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Proceso Flipped Learning  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe1995",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fuera del Aula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7556a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Docente:\n",
    "\n",
    "* Diseña y planea el proceso de enseñanza-aprendizaje del aula, integrando estrategias, modelos de enseñanza y metodologías (aprendizaje basado en proyectos, aprendizaje cooperativo y colaborativo,…).\n",
    "* Diseña y planea actividades que se realizarán fuera del aula (ver vídeos, cumplimentar cuestionarios,…).\n",
    "* Selecciona e integra la tecnología en actividades de aprendizaje activo.\n",
    "* Diseña actividades de evaluación que promuevan el aprendizaje del alumnado.\n",
    "\n",
    "### Alumnado:\n",
    "\n",
    "* Accede, cuantas veces necesite, a las actividades facilitadas por el profesorado.\n",
    "* Realiza las actividades propuestas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bec06a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## En el Aula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06ef89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Docente:\n",
    "\n",
    "* Guía y facilita los procesos de aprendizaje, atendiendo a la diversidad.\n",
    "* Retroalimenta el desempeño de los equipos/grupos y del alumnado individualmente.\n",
    "* Genera espacios para la coevaluación y autoevaluación.\n",
    "\n",
    "### Alumnado:\n",
    "\n",
    "* Realiza las actividades (debates, exposiciones orales, informes, diario de aprendizaje, cuaderno de trabajo cooperativo,…).\n",
    "* Recibe retroalimentación inmediata del profesorado y de sus compañeros y compañeras.\n",
    "* Accede, si fuera necesario, a las actividades previas facilitadas por el profesorado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c35435",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fomento de la lectura literaria asociada a Ingeniería agropecuaria y licenciatura en Matemáticas\n",
    "\n",
    "John Allen Paulos. El hombre anumérico. El analfabetismo matemático y sus consecuencias. \n",
    "\n",
    "\"Las mates siempre fueron mi asignatura más floja.\" \n",
    "\n",
    "<<Un millón de dólares, mil millones o un billón. No importa cuánto siempre y cuando hagamos algo por resolver el problema>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e5d5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36eb728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d38dd4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Objetivo de aprendizaje\n",
    "\n",
    "* Constituir un modelo de reconocimiento de imágenes con una red neuronal secuencial gracias a Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7261b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Establecimiento de prerrequisitos conceptuales para alcanzar el objetivo de aprendizaje trazado. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f7819",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Clasificación de imagenes del capítulo 3 de geron con un modelo lineal   \n",
    "* the perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298e976",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Para el diseño de la clase tenga en cuenta algunos problemas de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c1c1ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Digitalizar una imagen tomada con el celular. \n",
    "* usar la notación de corchetes para descomponer una fotografía en sus componentes 'red', green, blue. (RGB)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f7ef9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tereas para realizar antes de la clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c740a76e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Práctica de codificación de construcción de un modelo lineal de reconocimiento de imagenes con el mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb447c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tareas para realizar en clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c05e3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Constituir un modelo completo de reconocimiento de imagenes con el dataset fashion_mnist y una red neuronal secuencial.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f09f21c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chapter 10\n",
    "\n",
    "### Introduction to artificial neural networks with Keras  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495cf6e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An MLP is composed of one (passthrough) input layer, one or more layers of TLUs, called hidden layers, and one final layer of TLUs called the output layer (see Figure 10-7). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850675c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The layers close to the input layer are usually called the lower layers, and the ones close to the outputs are usually called the upper layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89994490",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Every layer except the output layer includes a bias neuron and is fully connected to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987e9dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "figure 10-7  \n",
    "\n",
    "<img src = 'https://github.com/marco-canas/7_didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/c_10_images/fig_10_7.png?raw=true'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63d2e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed945f28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The signal flows only in one direction (from the inputs to the outputs), so this architecture is an example of a feedforward neural network (FNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45c3bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementing MLPs with Keras  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac3787",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keras is a high-level Deep Learning API that allows you to easily build, train, evaluate, and execute all sorts of neural networks. Its documentation (or specification) is available at https://keras.io/. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747c6ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The reference implementation, also called Keras, was developed by François Chollet as part of a research project and was released as an open source project in March 2015. It quickly gained popularity, owing to its ease of use, flexibility, and beautiful design. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b567d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To perform the heavy computations required by neural networks, this reference implementation relies on a computation backend. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169cf84e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "At present, you can choose from three popular open source Deep Learning libraries: TensorFlow, Microsoft Cognitive Toolkit\n",
    "(CNTK), and Theano. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4982c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Therefore, to avoid any confusion, we will refer to this reference implementation as multibackend Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575a003",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since late 2016, other implementations have been released. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6cd2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can now run Keras on Apache MXNet, Apple’s Core ML, JavaScript or TypeScript (to run Keras code in a web browser), and PlaidML (which can run on all sorts of GPU devices, not just Nvidia). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec5179",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Moreover, TensorFlow itself now comes bundled with its own Keras implementation, tf.keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6450f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It only supports TensorFlow as the backend, but it has the advantage of offering some very useful extra features (see Figure 10-10): for example, it supports TensorFlow’s Data API, which makes it easy to load and preprocess data efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d05f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For this reason, we will use tf.keras in this book. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdec530",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, in this chapter we will not use any of the TensorFlow-specific features, so the code should run fine on other Keras implementations as well (at least in Python), with only minor modifications, such as changing the imports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da57da9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "figure 10_10\n",
    "<img src = 'https://github.com/marco-canas/7_didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/c_10_images/figure_10_10.png?raw=true'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd5c80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The most popular Deep Learning library, after Keras and TensorFlow, is Facebook’s PyTorch library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13980d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The good news is that its API is quite similar to Keras’s (in part because both APIs were inspired by Scikit-Learn and Chainer), so once you know Keras, it is not difficult to switch to PyTorch, if you ever want to. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717791d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "PyTorch’s popularity grew exponentially in 2018, largely thanks to its simplicity and excellent documentation, which were not TensorFlow 1.x’s main strengths. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6af169",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, TensorFlow 2 is arguably just as simple as PyTorch, as it has adopted Keras as its official high-level API and its developers have greatly simplified and cleaned up the rest of the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253bcd0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The documentation has also been completely reorganized, and it is much easier to find what you need now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d0d62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Similarly, PyTorch’s main weaknesses (e.g., limited portability and no computation graph analysis) have been largely addressed in PyTorch 1.0. Healthy competition is beneficial to everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8004d68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All right, it’s time to code! As tf.keras is bundled with TensorFlow, let’s start by installing TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834b4ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Installing TensorFlow 2 Assuming you installed Jupyter and Scikit-Learn by following the installation instructions in Chapter 2, use pip to install TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef96d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you created an isolated environment using virtualenv, you first need to activate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02771d6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "El sistema no puede encontrar la ruta especificada.\n",
      "El sistema no puede encontrar la ruta especificada.\n"
     ]
    }
   ],
   "source": [
    "!cd ML_PATH # Your ML working directory (e.g., $HOME/ml)\n",
    "\n",
    "!.\\my_env\\Scripts\\activate # on Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42832d9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, install TensorFlow 2 (if you are not using a virtualenv, you will need administrator rights, or to add the --user option):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450f0e28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
      "     -------------------------------------- 272.8/272.8 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.51.1)\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.8.tar.gz (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 2.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.29.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.12.6)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.22.1-cp310-abi3-win_amd64.whl (420 kB)\n",
      "     ------------------------------------ 420.6/420.6 kB 771.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Downloading ml_dtypes-0.0.4-cp310-cp310-win_amd64.whl (98 kB)\n",
      "     ---------------------------------------- 98.1/98.1 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\marco\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.8-py3-none-any.whl size=1439795 sha256=9f27c81f92b3a6c2dffbbd6dcb8bf47d5bed0c675d967a3625342ffd9fa9264e\n",
      "  Stored in directory: c:\\users\\marco\\appdata\\local\\pip\\cache\\wheels\\09\\6f\\35\\a8fac8b61de8e0d9eb07988481528898561923e260b1fa7d2f\n",
      "Successfully built jax\n",
      "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, ml-dtypes, keras, jax, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.11.0\n",
      "    Uninstalling tensorflow-estimator-2.11.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.0\n",
      "    Uninstalling tensorboard-2.11.0:\n",
      "      Successfully uninstalled tensorboard-2.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\Marco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\Marco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Marco\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac8453",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To test your installation, open a Python shell or a Jupyter notebook, then import TensorFlow and tf.keras and print their versions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918c97bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc40963",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea944b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The second version is the version of the Keras API implemented by tf.keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7a99a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that it ends with -tf, highlighting the fact that `tf.keras` implements the Keras API, plus some extra TensorFlow-specific features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e3f16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let’s use tf.keras! We’ll start by building a simple image classifier.\n",
    "Building an Image Classifier Using the Sequential API\n",
    "First, we need to load a dataset. In this chapter we will tackle Fashion\n",
    "MNIST, which is a drop-in replacement of MNIST (introduced in\n",
    "Chapter 3). It has the exact same format as MNIST (70,000 grayscale\n",
    "images of 28 × 28 pixels each, with 10 classes), but the images represent\n",
    "fashion items rather than handwritten digits, so each class is more diverse,\n",
    "and the problem turns out to be significantly more challenging than MNIST.\n",
    "For example, a simple linear model reaches about 92% accuracy on\n",
    "MNIST, but only about 83% on Fashion MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3964a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Keras to load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e799892",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keras provides some utility functions to fetch and load common datasets, including MNIST, Fashion MNIST, and the California housing dataset we used in Chapter 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d3e2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s load Fashion MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e91f6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8356b66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b791e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca03426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0a5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf869f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524633a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b6b0112",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tareas para realizar después de la realización de la clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947460e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Actividades de memorización: \n",
    "  - escucha reiterada de grabaciones de formulas y resultados científicos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a5567",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dificultades de aprendizaje detectados durante la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c6c7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb9402bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estrategias propuestas para la solución de las dificultades de aprendizaje detectadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3bd5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11570a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cuestionario para realizar labores de memorización y observación,  a la síntesis de la información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f0ec1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "236b43fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grabaciones en audio para fomentar la capacidad de memorizar enunciados de teoremas y resultados científicos y la capacidad de parafrasear estos resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f2ffa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Se dispondrá de un lugar en el drive asociuado al correo institucional de la Universidad Nacional del Profesor Marso para albergar los archivosd de audio de fomento a la memoirización, enunciación y parafraseo de los resultados científicos, prtopiedades, reglas, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564fa59d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparta sus cuadernos y videos, evidencias de su aprendizaje [aquí](https://forms.office.com/Pages/ResponsePage.aspx?id=IefhmYRxjkmK_7KtTlPBwkanXIs1i1FEujpsZgO6dXpUMEMwTEZVMzEwVVBPTElWNVg5OVEyWUhMUy4u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe498b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44be6d93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8dfed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee46cb9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mapa conceptual que vincula los conceptos asoaciados al objetivo de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf552488",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0266e3c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quiz de 5 minutos para ejercitación y adquisición de habilidades "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b127f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10bce0d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referentes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3c468",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* [stewart precálculo]()\n",
    "* [stewart cálculo]()\n",
    "* [larson]()\n",
    "\n",
    "* []()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e56a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Evaluamos al profesor Marco Cañas Aquí](https://forms.office.com/Pages/ResponsePage.aspx?id=IefhmYRxjkmK_7KtTlPBwkanXIs1i1FEujpsZgO6dXpUREJPV1kxUk1JV1ozTFJIQVNIQjY5WEY3US4u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f43536",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Continue su aprendizaje en la siguiente clase a través del siguiente [vínculo]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc9115",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conjeturas pedagógicas fruto de la aplicación del modelo de aprendizaje invertido y del enfoque hacia la ciencia de datos con python\n",
    "\n",
    "1. Todo cálculo o resultado debe ser interpretado en una línea markdown en la línea del cuaderno Jupyter, inmediatamente después de la enunciación del resultado y después de la presentación de una tabla o gráfico bidimensional, de tal menera que el estudiante explicite la comprensión verbal del resultado y las inferencias o estrategias que este resultado le sugieren.   \n",
    "\n",
    "\n",
    "### Agradecimientos  \n",
    "\n",
    "Doy gracias a Dios por la vida de mi Hijo Joseph Cañas Osorio y la madurez que ha alcanzado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080a840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
